{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE 421 Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMPeizQx9XVE"
      },
      "source": [
        "**CSCE 421 Final Project: Chess Position Evaluation**\n",
        "\n",
        "Problem formulation: How can we train a computer to learn the game of chess (or more generally, any board game) with as little human interference (or hard-coded knowledge beyond the gameâ€™s rules) proficiently enough to outperform its human (and hard-coded engine) counterparts?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvcs13wbu_xK"
      },
      "source": [
        "# import useful libraries:\n",
        "import chess # python-chess library\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nap_mjlxr2Nm"
      },
      "source": [
        "# define hyperparameters:\n",
        "num_epochs = 2 # number of times we iterate over the entire training dataset\n",
        "batch_size = 4 # number of examples per training iteration\n",
        "test_size = 0.2 # size of test set\n",
        "NUM_POSITIONS = 1000000 # number of positions to extract & parse from the input dataset (0 for all)\n",
        "INPUT_FILE_START_INDEX = 0 # which line in the input file do we start importing positions from?\n",
        "learning_rate = 0.0001 # the learning rate of the network\n",
        "optimizer_momentum = 0.9 # the momentum parameter of the optimizer object\n",
        "MODEL_FILEPATH = 'drive/My Drive/Colab Notebooks/CSCE_421_Final/trained_model.pt' # the filepath of the saved model\n",
        "LOAD_MODEL = True # True to load the trained model from file, False to make one from scratch\n",
        "SAVE_MODEL = True # True to save the model after training"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8dH8Gxf9lVK"
      },
      "source": [
        "**Loading the Data**: \n",
        "\n",
        "We import the positions dataset, containing FEN-strings (a popular way to encode chess positions) and their respective engine evaluation in centipawns (a popular computer-chess method for evaluating positions). Evaluations were created using the Stockfish chess engine (https://stockfishchess.org/), one of the world's best chess engines, while looking 22 moves ahead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNQhzWV2PfGi",
        "outputId": "7a0c19e2-7b00-4298-a788-3a69902cfa13"
      },
      "source": [
        "# mount Google Drive (for input file)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PRDO0VcOUZ0"
      },
      "source": [
        "# open input file:\n",
        "f = open('drive/My Drive/Colab Notebooks/CSCE_421_Final/chessData.csv')\n",
        "\n",
        "# ignore first line (header) in the CSV file:\n",
        "f.readline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpbXG-umPRyK"
      },
      "source": [
        "# skip the file pointer to the start index:\n",
        "for i in range(INPUT_FILE_START_INDEX):\n",
        "  f.readline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV9LjwyFI97B"
      },
      "source": [
        "We define a utility function to convert a line of input (from the CSV file) to tensor input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwOQcKU4wLXC"
      },
      "source": [
        "# ----- Utility function to convert FEN string to bitboard -----\n",
        "\n",
        "# global arrays to avoid redundant code:\n",
        "PIECES = [chess.PAWN, chess.ROOK, chess.KNIGHT, chess.BISHOP, chess.QUEEN, chess.KING]\n",
        "COLORS = [chess.WHITE, chess.BLACK]\n",
        "\n",
        "def FEN_to_bitboard(position, return_float=False):\n",
        "  FEN, score = position.split(',')\n",
        "\n",
        "  if score.startswith('#+'):\n",
        "      score = '20000'\n",
        "  elif score.startswith('#-'):\n",
        "      score = '-20000'\n",
        "\n",
        "  # import the FEN to a board object:\n",
        "  board = chess.Board(FEN)\n",
        "\n",
        "  # get the int values of each piece and store in bitboard list:\n",
        "  bitboard = []\n",
        "  for color in COLORS:\n",
        "    for piece in PIECES:\n",
        "      # get the int value of the piece:\n",
        "      piece_int = int(board.pieces(piece, color))\n",
        "\n",
        "      # convert the piece int value to a 64-bit binary string:\n",
        "      piece_bin = [int(i) for i in format(piece_int, '064b')]\n",
        "      # reshape the 64-bit array into 2d 8x8 array:\n",
        "      piece_bin = np.reshape(piece_bin, (-1, 8))\n",
        "\n",
        "      # add these as array indices to the bitboard:\n",
        "      bitboard.append(piece_bin)\n",
        "\n",
        "  # if return_float is True, return a FloatTensor of the board\n",
        "  # otherwise, save memory with ByteTensor:\n",
        "  if return_float:\n",
        "    return torch.FloatTensor(bitboard), torch.FloatTensor([int(score)])\n",
        "  else:\n",
        "    return torch.ByteTensor(bitboard), torch.ByteTensor([int(score)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GTa02vcXmRV"
      },
      "source": [
        "Define a function to load positions (as bitboards) from the CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfswaC0Q8FDq"
      },
      "source": [
        "# create the mini-batch data loader (load n data points from filestream f):\n",
        "def get_data(filestream, n=1000, PRINT_INDICATOR=100000):\n",
        "  data = []\n",
        "  count = 0\n",
        "\n",
        "  if n == 0:\n",
        "    for line in filestream.readlines():\n",
        "      count += 1\n",
        "      try:\n",
        "        data.append(FEN_to_bitboard(line))\n",
        "      except:\n",
        "        # undo the counter:\n",
        "        count -= 1\n",
        "      if count % PRINT_INDICATOR == 0: print(count)\n",
        "  else:\n",
        "    for i in range(n):\n",
        "      try:\n",
        "        data.append(FEN_to_bitboard(filestream.readline()))\n",
        "        count += 1\n",
        "      except: pass\n",
        "      if count % PRINT_INDICATOR == 0: print(count)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QRCDglO9CR-T",
        "outputId": "51965760-73a0-4b80-dd7f-38dec72c1b30"
      },
      "source": [
        "# inport and parse the data from the CSV file (only around 5,000,000 datapoints will fit in memory):\n",
        "data = get_data(f, NUM_POSITIONS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OIP9ZSFeMDlE"
      },
      "source": [
        "# split data into training and testing sets:\n",
        "len_traindata = int((1 - test_size) * NUM_POSITIONS)\n",
        "len_testdata = NUM_POSITIONS - len_traindata\n",
        "\n",
        "train_data = data[0:len_traindata]\n",
        "test_data = data[len_traindata:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HQwLsuQvOiD5"
      },
      "source": [
        "# create the PyTorch data loaders:\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxPwnqnNYMVt"
      },
      "source": [
        "**Creating the Neural Network**\n",
        "\n",
        "Architecture: a 5-layer convolutional neural network, consisting of 2 convolutional layers and 3 fully-connected layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QghwRhRwYm9M"
      },
      "source": [
        "# create a convolutional neural network:\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    #input shape (batch_size, 12, 8, 8)\n",
        "    self.conv1 = nn.Sequential(\n",
        "                    nn.Conv2d(in_channels=12, out_channels=500, kernel_size=3, padding=2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(kernel_size=2)\n",
        "                 )\n",
        "    #output shape (batch_size, 500, 5, 5)\n",
        "    \n",
        "    self.conv2 = nn.Sequential(nn.Conv2d(500, 250, 2, 1, 2), \n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2)\n",
        "                 )\n",
        "    #output shape (batch_size, 250, 4, 4)\n",
        "    \n",
        "    self.fc1 = nn.Linear(250*4*4, 100)\n",
        "    self.fc2 = nn.Linear(100, 20)\n",
        "    self.out = nn.Linear(20, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # apply convolutional layers:\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "\n",
        "    #Flatten\n",
        "    x = x.view(-1, 250*4*4)\n",
        "\n",
        "    # apply linear layers:\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXdEf8BJO8U5"
      },
      "source": [
        "## Instantiate the network:\n",
        "net = CNN()\n",
        "if LOAD_MODEL:\n",
        "  net.load_state_dict(torch.load(MODEL_FILEPATH))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfxaN3ijO_uJ"
      },
      "source": [
        "# define a loss function and an optimizer:\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=optimizer_momentum)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2UjgP6sPBho"
      },
      "source": [
        "# define a train function to train the network:\n",
        "def train(net, num_epochs, PRINT_ITERATIONS=100000, RECORD_ITERATIONS=1000):\n",
        "  losses = []\n",
        "  for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0): \n",
        "      # convert inputs to float (on-the-spot for saving memory):\n",
        "      inputs = inputs.type(torch.FloatTensor)\n",
        "      labels = labels.type(torch.FloatTensor)\n",
        "\n",
        "      # zero the parameter gradients:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # feedforward:\n",
        "      outputs = net(inputs)\n",
        "      # print(outputs)\n",
        "      # break\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # backpropagation & optimization:\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # record loss every RECORD_ITERATIONS mini-batches\n",
        "      if np.isnan(loss.item()):\n",
        "        print(i)\n",
        "        return losses\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if (i+1) % RECORD_ITERATIONS == 0:\n",
        "        losses.append(running_loss / PRINT_ITERATIONS)\n",
        "        running_loss = 0.0\n",
        "\n",
        "      # print update every PRINT_ITERATIONS mini-batches\n",
        "      if (i+1) % PRINT_ITERATIONS == 0:\n",
        "        print('\\t%d iterations so far.' % (i+1))\n",
        "    \n",
        "    print('---------- EPOCH #%d FINISHED ----------' % epoch)\n",
        "    # save the model after every epoch (just in case):\n",
        "    if SAVE_MODEL:\n",
        "      torch.save(net.state_dict(), MODEL_FILEPATH)\n",
        "\n",
        "  print('Finished Training')\n",
        "  return losses"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2cmvHr8UPQYZ"
      },
      "source": [
        "# train the network:\n",
        "losses = train(net, num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fDpy4t53VxFj"
      },
      "source": [
        "# function to plot loss over training:\n",
        "def plot_loss(losses):\n",
        "  plt.plot(range(len(losses)), losses)\n",
        "  plt.title('Training Loss')\n",
        "  plt.xlabel('Iteration (1k training batches)')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bmOGcIsmUByO"
      },
      "source": [
        "# save the model:\n",
        "if SAVE_MODEL:\n",
        "  torch.save(net.state_dict(), MODEL_FILEPATH)\n",
        "  print('New/Updated model saved to %s' % MODEL_FILEPATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mhtBKtDOLs"
      },
      "source": [
        "**Creating the Chess Engine**\n",
        "\n",
        "The chess engine consists of the trained network and uses minimax with alpha-beta pruning to evaluate moves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Boj2ML5pgPoS"
      },
      "source": [
        "# a function to evaluate a position (done here for clarity):\n",
        "MATERIAL_SCORES = [100, 500, 275, 325, 900, 10000, -100, -500, -275, -325, -900, -10000]\n",
        "def evaluate_position(board, add_material_score=False):\n",
        "  # convert board to bitboard of type tensor.FloatTensor:\n",
        "  board = FEN_to_bitboard(board.fen() + \", 0\", return_float=True)[0]\n",
        "\n",
        "  # add extra dimension:\n",
        "  board = board[None]\n",
        "\n",
        "  # evaluate:\n",
        "  evaluation = net(board) # the network's evaluation\n",
        "\n",
        "  if add_material_score:\n",
        "    # calculate material score:\n",
        "    material = 0\n",
        "    for i, piece_score in enumerate(MATERIAL_SCORES):\n",
        "      material += sum(sum(board[0][i])) * piece_score\n",
        "    evaluation += material\n",
        "\n",
        "  return evaluation.item()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zziTXr3fDJyd"
      },
      "source": [
        "# the decision-making function. minimax with alpha-beta pruning:\n",
        "INF = 1e9\n",
        "WHITE = True\n",
        "BLACK = False\n",
        "\n",
        "def engine(board, depth, maximizingPlayer):\n",
        "  return str(alphabeta(board, depth, -INF, INF, maximizingPlayer)[1])\n",
        "\n",
        "def alphabeta(board, depth, alpha, beta, maximizingPlayer):\n",
        "  if depth == 0 or board.is_game_over():\n",
        "    return evaluate_position(board, False), None # 'None' is just a placeholder\n",
        "  if maximizingPlayer:\n",
        "    value = -INF\n",
        "    bestmove = None\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move) # make the move\n",
        "      move_score = alphabeta(board, depth-1, alpha, beta, False)[0]\n",
        "      if move_score > value:\n",
        "        value = move_score\n",
        "        bestmove = move\n",
        "      alpha = max(alpha, value)\n",
        "      if alpha >= beta:\n",
        "        break # beta cutoff\n",
        "      board.pop() # undo the move\n",
        "    return value, bestmove\n",
        "  else:\n",
        "    value = INF\n",
        "    bestmove = None\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move) # make the move\n",
        "      move_score = alphabeta(board, depth-1, alpha, beta, False)[0]\n",
        "      if move_score < value:\n",
        "        value = move_score\n",
        "        bestmove = move\n",
        "      beta = min(beta, value)\n",
        "      if beta <= alpha:\n",
        "        break # alpha cutoff\n",
        "      board.pop() # undo the move\n",
        "    return value, bestmove"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LatxZRfDaBs7"
      },
      "source": [
        "Below is an example of the neural network deciding the best move in the given position:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "q7U2pDW6M-l0",
        "outputId": "377b5df4-e1ac-4b51-aa65-b95b1dce9208"
      },
      "source": [
        "FEN = \"r1b3k1/pp1nb1pp/4p3/3pP3/3q4/P2B1P2/1PQB3P/R3K2R w KQ - 0 17\"\n",
        "board = chess.Board(FEN)\n",
        "engine(board, 3, WHITE)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'d3h7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    }
  ]
}